import pandas as pd
import numpy as np
import requests
import json
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.arima.model import ARIMA
from tqdm import tqdm
from datetime import datetime
import warnings
warnings.filterwarnings("ignore")

# 配置参数
api_key = "sk-cqmbzsrduocuwebkbjgixiugrcnwwzfihlhcjmesqsapdhul"
base_url = "https://api.siliconflow.cn/v1"
EXCEL_PATH = "data.xlsx"
MODEL_NAME = "ft:LoRA/Qwen/Qwen2.5-7B-Instruct:yok9x3mcov:predict1:rwqmskiqvgylngwczitp-ckpt_step_450"
WINDOW_SIZE = 24
MAX_RETRIES = 5
ENSEMBLE_WEIGHT = 0.7
DYNAMIC_TREND_WINDOW = 3
CONFIDENCE_LEVEL = 0.99
TREND_SENSITIVITY = 17  
BASE_TEMP = 0.1      

def prepare_data():
    df = pd.read_excel(EXCEL_PATH)
    time_col = next((col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()), None)
    numeric_col = df.select_dtypes(include=np.number).columns[0]
    full_data = df[numeric_col].values.astype(np.float32)
    train = full_data[:-1210 - WINDOW_SIZE]
    valid = full_data[-1210 - WINDOW_SIZE:]    
    if time_col:
        timestamps = df[time_col].iloc[-1210 - WINDOW_SIZE:].reset_index(drop=True)
    else:
        timestamps = pd.Series(pd.date_range(start='2023-01-01', periods=len(valid), freq='h'))    
    scaler = RobustScaler(quantile_range=(10, 90))
    train_scaled = scaler.fit_transform(train.reshape(-1, 1))
    valid_scaled = scaler.transform(valid.reshape(-1, 1)).flatten()    
    return scaler, valid_scaled, timestamps

def create_sequences(data, window_size):
    X, y = [], []
    for i in range(len(data) - window_size):
        window = data[i:i+window_size]
        long_trend = np.polyfit(np.arange(window_size), window, 1)[0]
        mid_trend = np.polyfit(np.arange(window_size//2, window_size), window[-window_size//2:], 1)[0]
        short_trend = np.polyfit(np.arange(window_size-DYNAMIC_TREND_WINDOW, window_size), 
                                window[-DYNAMIC_TREND_WINDOW:], 1)[0] if DYNAMIC_TREND_WINDOW >=2 else 0
        X.append(np.concatenate([window, [long_trend, mid_trend, short_trend]]))
        y.append(data[i+window_size])
    return np.array(X), np.array(y)

def arima_predict(history):
    try:
        model = ARIMA(history, order=(3,1,2))
        model_fit = model.fit()
        forecast = model_fit.get_forecast(steps=1, alpha=1-CONFIDENCE_LEVEL)
        return forecast.predicted_mean[0], forecast.conf_int().iloc[0,0], forecast.conf_int().iloc[0,1]
    except:
        point = np.mean(history[-3:])
        spread = point * 0.15
        return point, point - spread, point + spread

def adaptive_predictor(seq, scaler):
    global TREND_SENSITIVITY      
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}    
    window = seq[:-3].astype(float)
    long_trend = float(seq[-3])
    mid_trend = float(seq[-2])
    short_trend = float(seq[-1])  
    original_window = scaler.inverse_transform(window.reshape(-1, 1)).flatten()
    if len(original_window) >= 2:
        prev = original_window[-2]
        current = original_window[-1]
        change = abs(current - prev)/(abs(prev) + 1e-8)
    else:
        change = 0

    temp_base = BASE_TEMP + 0.3 * min(1, abs(short_trend)*5)
    dynamic_weight_base = ENSEMBLE_WEIGHT + 0.2 * np.tanh(short_trend * TREND_SENSITIVITY / 10)  
    if change > 0.35:
        temp = min(temp_base + 0.25, 1.0)
        dynamic_weight = min(dynamic_weight_base + 0.2, 0.95)
        TREND_SENSITIVITY = min(15, TREND_SENSITIVITY + 4)  
    else:
        temp = temp_base
        dynamic_weight = dynamic_weight_base
        TREND_SENSITIVITY = max(8, TREND_SENSITIVITY - 1)   

    prompt = f"""作为预测模型，请基于以下特征预测下个值：
    趋势参数：
    - 长期趋势：{long_trend:.4f}
    - 中期趋势：{mid_trend:.4f}
    - 短期趋势：{short_trend:.4f}
    最近{DYNAMIC_TREND_WINDOW}项值：{window[-DYNAMIC_TREND_WINDOW:].round(4).tolist()}
    输出要求：
    1. 严格正值（≥0.001）
    2. 考虑{int(CONFIDENCE_LEVEL*100)}%置信区间需求
    3. 格式：0.123
    预测值："""
    
    for _ in range(MAX_RETRIES):
        try:
            response = requests.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json={
                    "model": MODEL_NAME,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temp,
                    "max_tokens": 15
                },
                timeout=35
            )
            if response.ok:
                content = json.loads(response.text)['choices'][0]['message']['content']
                numbers = [float(s) for s in content.replace(',','').split() 
                          if s.replace('.','',1).isdigit()]
                if numbers:
                    raw_pred = max(numbers[0], 0.001)
                    arima_point, arima_lower, arima_upper = arima_predict(window)
                    
                    final_point = dynamic_weight*raw_pred + (1-dynamic_weight)*arima_point
                    final_point = max(final_point, 0.001)
                    
                    hist_std = np.std(window[-6:])
                    model_diff = abs(raw_pred - arima_point)
                    spread = max(0.3*hist_std, 0.9*model_diff, 0.1) if change > 0.35 else max(0.2*hist_std, 0.7*model_diff, 0.08)
                    
                    lower = final_point - spread*1.2
                    upper = final_point + spread*0.8
                    
                    return final_point, max(lower, 0.001), upper
        except:
            continue
    return max(np.mean(window[-3:]), 0.001), 0.001, max(np.mean(window[-3:])*1.5, 0.001)

def post_process(predictions, lowers, uppers, y_true):
    historical_predictions = predictions[:-1]  
    historical_y_true = y_true[:len(predictions) - 1]  
    err = historical_predictions - historical_y_true
    dynamic_alpha = 0.5 * (1 + np.tanh(err))
    corrected = predictions[:-1] - dynamic_alpha * pd.Series(err).rolling(6, min_periods=1).mean().values
    last_prediction = predictions[-1]
    corrected = np.append(corrected, last_prediction)  
    residuals = y_true[:len(corrected)] - corrected
    residual_std = np.std(residuals[:-1]) if len(residuals) > 1 else 0  
    
    new_lower = corrected - 1.5 * residual_std
    new_upper = corrected + 1.5 * residual_std

    final_lower = 0.3 * np.array(lowers) + 0.7 * new_lower
    final_upper = 0.3 * np.array(uppers) + 0.8 * new_upper
    
    corrected = np.maximum(corrected, 0)
    final_lower = pd.Series(np.maximum(final_lower, 0)).ewm(alpha=0.2).mean().values
    final_upper = pd.Series(np.maximum(final_upper, corrected)).ewm(alpha=0.2).mean().values
    return corrected, final_lower, final_upper

def main():
    scaler, valid_scaled, timestamps = prepare_data()
    X_valid, y_valid = create_sequences(valid_scaled, WINDOW_SIZE)
    
    predictions, lowers, uppers = [], [], []
    for seq in tqdm(X_valid, desc="动态预测"):
        point, lower, upper = adaptive_predictor(seq, scaler)
        predictions.append(point)
        lowers.append(lower)
        uppers.append(upper)
    
    predictions = scaler.inverse_transform(np.array(predictions).reshape(-1,1)).squeeze()
    lowers = scaler.inverse_transform(np.array(lowers).reshape(-1,1)).squeeze()
    uppers = scaler.inverse_transform(np.array(uppers).reshape(-1,1)).squeeze()
    y_true = scaler.inverse_transform(y_valid.reshape(-1,1)).squeeze()
    
    predictions, lowers, uppers = post_process(predictions, lowers, uppers, y_true)
    
    min_len = min(len(predictions), len(lowers), len(uppers))
    aligned_ts = timestamps.iloc[WINDOW_SIZE:WINDOW_SIZE+min_len].reset_index(drop=True)
    
    results_df = pd.DataFrame({
        'Timestamp': aligned_ts,
        'TrueValue': y_true[:min_len],
        'Prediction': predictions[:min_len],
        'LowerBound': lowers[:min_len],
        'UpperBound': uppers[:min_len]
    })
    
    assert (results_df['LowerBound'] <= results_df['UpperBound']).all(), "区间异常"
    assert (results_df['LowerBound'] >= 0).all(), "负下限存在"
    
    results_df.to_excel(
        f'optimized_predictions_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx',
        index=False,
        float_format="%.4f"
    )
    
    mae = mean_absolute_error(results_df['TrueValue'], results_df['Prediction'])
    rmse = np.sqrt(mean_squared_error(results_df['TrueValue'], results_df['Prediction']))
    coverage = ((results_df['TrueValue'] >= results_df['LowerBound']) & 
               (results_df['TrueValue'] <= results_df['UpperBound'])).mean()
    
    from scipy.stats import pearsonr
    true_diff = np.diff(results_df['TrueValue'])
    pred_diff = np.diff(results_df['Prediction'])
    trend_corr, _ = pearsonr(true_diff, pred_diff[:len(true_diff)])
    
    print(f"MAE: {mae:.4f}  RMSE: {rmse:.4f}")
    print(f"区间覆盖率: {coverage:.1%}  趋势相关系数: {trend_corr:.3f}")
    
    plt.figure(figsize=(24, 12))
    plt.plot(results_df['Timestamp'], results_df['TrueValue'], 
            label='true', linewidth=2, color='#2ca02c')
    plt.plot(results_df['Timestamp'], results_df['Prediction'], 
            label='pre', linestyle='--', linewidth=1.8, color='#d62728')
    plt.fill_between(results_df['Timestamp'], 
                    results_df['LowerBound'],
                    results_df['UpperBound'],
                    color='#ff7f0e', alpha=0.2, label=f'{int(CONFIDENCE_LEVEL*100)}%预测区间')
    
    plt.text(0.02, 0.92, 
            f"MAE: {mae:.3f}\nRMSE: {rmse:.3f}\nCoverage: {coverage:.1%}\nTrend Corr: {trend_corr:.3f}",
            transform=plt.gca().transAxes,
            verticalalignment='top',
            bbox=dict(boxstyle='round', alpha=0.1))
    
    plt.title("预测效果", fontsize=16)
    plt.xticks(rotation=40)
    plt.grid(True, alpha=0.25)
    plt.legend(loc='upper left')
    
    plt.figure(figsize=(24, 6))
    plt.plot(results_df['Timestamp'].iloc[1:], true_diff, 
            label='真实变化率', alpha=0.6, color='#1f77b4')
    plt.plot(results_df['Timestamp'].iloc[1:], pred_diff[:len(true_diff)], 
            label='预测变化率', linestyle='--', color='#ff7f0e')
    plt.title('趋势响应对比', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.2)
    plt.tight_layout()
    
    plt.show()

if __name__ == "__main__":
    main()